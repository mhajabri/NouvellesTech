<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta content="IE=edge" http-equiv="X-UA-Compatible">
    <meta content="width=device-width,initial-scale=1" name="viewport">
    <meta content="description" name="description">
    <meta name="google" content="notranslate"/>
    <meta content="Mashup templates have been developped by Orson.io team" name="author">

    <!-- Disable tap highlight on IE -->
    <meta name="msapplication-tap-highlight" content="no">

    <link rel="robot-icon" sizes="180x180" href="./assets/robot-icon-180x180.png">
    <link href="./assets/robot-icon-180x180.ico" rel="icon">

    <title>RL - VeilleTech</title>

    <link href="./main.3f6952e4.css" rel="stylesheet">
</head>

<body class="">
<div id="site-border-left"></div>
<div id="site-border-right"></div>
<div id="site-border-top"></div>
<div id="site-border-bottom"></div>
<!-- Add your content of header -->
<header>
    <nav class="navbar  navbar-fixed-top navbar-default">
        <div class="container">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar-collapse"
                    aria-expanded="false">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>

            <div class="collapse navbar-collapse" id="navbar-collapse">
                 <ul class="nav navbar-nav ">
                    <li><a href="./index.html" title="">Home</a></li>
                    <li><a href="./intro.html" title="">Introduction</a></li>
                    <li><a href="./article1.html" title="">Bases théoriques du RL</a></li>
                    <li><a href="./article2.html" title="">Applications du RL</a></li>
                    <li><a href="./article3.html" title="">RL & Finance</a></li>
                    <li><a href="./news.html" title="">Ressources</a></li>
                </ul>


            </div>
        </div>
    </nav>
</header>
    
    
<div class="section-container">
    <div class="container">
        <div class="row">
            <div class="col-xs-12">
                <img src="./assets/images/work001-01.jpg" class="img-responsive" alt="">
                <div class="card-container">
                    <div class="text-center">
                        <h1 class="h2">Applications of RL in Real World</h1>
                    </div>
                    <p style="text-align:center; font-size:120%;">Cet article présente met la lumière sur diverses applications de RL 
                        dans l'industrie </p>

                </div>
            </div>


            <div class="col-md-8 col-md-offset-2 section-container-spacer">
                <div class="row">
                    <div class="col-xs-12 col-md-6">
                        <img src="./assets/images/gaming_rl.png" class="img-responsive" alt="">
                        <p>Reinforcement Learning & Gaming</p>
                    </div>
                    <div class="col-xs-12 col-md-6">
                        <img src="./assets/images/robotics_rl.jpeg" class="img-responsive" alt="">
                        <p>Reinforcement Learning & Robotics</p>
                    </div>
                </div>
            </div>

            <div class="col-xs-12">

                <p style="text-align:justify; font-size:160%; font-weight:400;">&emsp;
                    Alors que les techniques de Deep Learning deviennent de plus en plus utilisées en industrie, notamment
                    à cause de leurs applications en vision et en NLP, le Reinforcement Learning semble être pour le moment 
                    sous-évalué.<br>
                    En outre, il semble qu'il y ait peu de ressources pour expliquer en détail comment le RL est appliquée dans
                    différentes industries. <br>
                    Ceci dit, l'apprentissage par renforcement ne devrait pas être négligé dans la
                    recherche en entreprise, étant donné son énorme potentiel d'aide à la prise de décision. 
                    Comme l'a dit Koray Kavukcuoglu, directeur de la recherche chez Deepmind :
                </p>
                    
                    <blockquote>
                        <p>“Combination of DL and RL is the best answer we have so far in terms of learning very good state
                            representations of challenging tasks to solve challenging real world problems.”</p>
                        <small class="pull-right">Koray Kavukcuoglu</small>
                    </blockquote>
                
                <div style="height:10px;font-size:10px;">&nbsp;</div>
                <p style="text-align:justify; font-size:160%; font-weight:400;">&emsp;
                    Par conséquent, le présent article vise à examiner l'étendue des applications du RL
                    dans le monde réel à l'heure actuelle, le lien du RL à d'autres domaines ainsi que le potentiel 
                    d'utilisation du RL dans le futur.
                </p>

                <div style="height:30px;font-size:30px;">&nbsp;</div>
                <p style="text-align:justify; font-size:200%; font-weight:600;">
                    <b>Applications du Reinforcement Learning</b>
                </p>
                
                <div style="height:15px;font-size:15px;">&nbsp;</div>
                <p style="text-align:justify; font-size:150%; font-weight:500;">
                    <b>Gestion de feux de signalisation</b>
                </p>
                
                <p style="text-align:justify; font-size:160%; font-weight:400;">&emsp;
                    Dans l'article "Reinforcement learning-based multi-agent system for network traffic signal control"[3], 
                    on essaie de concevoir un contrôleur de feux de signalisation pour résoudre le problème de congestion.<br> 
                    Testées uniquement sur un environnement simulé, leurs méthodes ont donné des résultats 
                    supérieurs à ceux des méthodes traditionnelles et ont mis en lumière les utilisations potentielles 
                    de multi-agent RL dans la conception des systèmes de circulation.<br>
             
                    Cinq agents ont été placés dans le réseau de circulation à cinq intersections, avec un agent de RL 
                    à l'intersection centrale pour contrôler la signalisation routière. L'état a été défini comme un vecteur à
                    huit dimensions, chaque élément représentant le flux de trafic relatif de chaque voie. Huit choix s'offraient 
                    à l'agent, chacun représentant une combinaison de phases, et la fonction de récompense était définie comme 
                    la réduction du délai par rapport au pas de temps précédent. 
                </p>
                
                <div style="height:20px;font-size:20px;">&nbsp;</div>
                <p align="center">
                    <img src="./assets/images/rl_traffic.PNG" class="img-responsive" alt="" align="middle">
                </p>
                <p></p>
            
                
                <div style="height:30px;font-size:30px;">&nbsp;</div>
                <p style="text-align:justify; font-size:150%; font-weight:500;">
                    <b>Robotique</b>
                </p>
                
                <p style="text-align:justify; font-size:160%; font-weight:400;">&emsp;
                    Il y a un travail colossal sur l'application de RL en robotique. En particulier, [11] a formé un robot 
                    pour qu'il apprenne les politiques de mise en correspondance des images-vidéo brutes avec les actions du robot.
                    Les images RVB ont été transmises à un CNN et les sorties étaient les couples moteur. <br>
                    L'élément RL était la recherche politique guidée pour générer des données sur la formation qui provenaient 
                    de sa propre répartition par État. <br>
                    Voici une vidéo de la chercheuse à MIT auteur de ce travail.
                </p>
                
                <p align="center">
                    <iframe width="784" height="441" src="https://www.youtube.com/embed/Q4bMcUk6pcw"
                            frameborder="0" allow="accelerometer;encrypted-media; gyroscope; picture-in-picture" allowfullscreen>

                    </iframe>
                </p>

                
                <div style="height:30px;font-size:30px;">&nbsp;</div>
                <p style="text-align:justify; font-size:150%; font-weight:500;">
                    <b>Gaming</b>
                </p>

                <p style="text-align:justify; font-size:160%; font-weight:400;">&emsp;
                    Le Reinforcement Learning est devenu beaucoup plus connu de nos jours parce que c'est l'algorithme principal 
                    utilisé pour résoudre différents jeux et parfois atteindre des performances surhumaines.<br>
                    Les plus célèbres d'entre sont AlphaGo[12] et AlphaGo Zero[13], mis en place par DeepMind (une équipe de Google),
                    qui ont été très médiatisé à tel point qu'un documentaire a par la suite été fait autour d'eux (disponible sur Netflix 
                    et autres plateformes).<br>
                    AlphaGo, qui a été entrainé avec des millions de parties jouées par des humains, avait déjà atteint une 
                    performance surhumaine et d'excellent résultats grâce au champion du monde en place. Pourtant, les chercheurs 
                    ont réfléchi plus tard et ont essayé de purifier leur travail en apportant le minimum d'expertise possible : en d'autres
                    termes, le but était de créer un modèle sans Domain Knowledge, sans voir les parties d'autres humains mais seulement 
                    en jouant contre soi-même jusqu'à ce qu'on apprennne à jouer, d'où le nm "Zero". Cette approche s'est révelée fructueuse puisque
                    finalement le nouvel agent, AlphaGo Zero, a joué contre l'original AlphaGo et lui a infligé 100-0.
                </p>
                
                
                <div style="height:30px;font-size:30px;">&nbsp;</div>
                <p style="text-align:justify; font-size:200%; font-weight:600;">
                    <b>Lien entre RL et autres domaines</b>
                </p>
                
                <p style="text-align:justify; font-size:160%; font-weight:400;">&emsp;
                    RL a une relation très étroite avec la <b>psychologie, la biologie et les neurosciences.</b> <br>
                    Comme dit auparavant, ce que fait un agent de n'est qu'un essai-erreur : il apprend à quel point ses actions
                    sont bonnes ou mauvaises en fonction des récompenses qu'il reçoit de l'environnement. Et c'est exactement comme ça 
                    que l'homme apprend  à prendre une décision. Par ailleurs, le problème de l'exploration et de l'exploitation ou encore
                    les tentatives de modélisation de l'environnement sont aussi des problèmes auxquels 
                    nous sommes confrontés dans notre vie quotidienne.<br>
                    
                    La théorie de <b>l'économie</b> peut aussi éclairer un peu la question de la RL. En particulier, 
                    l'analyse de l'apprentissage du renforcement multi-agent (MARL) peut être comprise à partir des perspectives 
                    de la théorie des jeux, qui est un domaine de recherche développé par John Nash pour comprendre les interactions 
                    des agents dans un système.
                </p>

                
                
                <div style="height:30px;font-size:30px;">&nbsp;</div>
                <p style="text-align:justify; font-size:200%; font-weight:600;">
                    <b>Potentiels d'utilisations futures</b>
                </p>
                
                <p style="text-align:justify; font-size:160%; font-weight:400;">&emsp;
                    La complexité des modélisations de Reinforcement Learning fait qu'il n'a pas été vulgarisé comme d'autres branches
                    de Machine Learning et qu'il ne peut donc pas être utilisé facilement. <br>
                    Cependant, voici deux tâches par lequelles le RL pourrait avoir un impact important à l'avenir : </p>
                    
                    <ul style="text-align:justify; font-size:160%; font-weight:400;">
                    <li><b>Créer des Assistants d'Humains plus intelligents :</b> En médecine, des chercheurs sont entrain d'explorer si le RL peut permettre de crée
                    des assistants virtuels pouvant aider lors du diagnostis, prescription ... etc. Dans un cadre plus général, on peut
                    imaginer un assistant virtuel travaillant avec bous et prenant bos actions dans ses considérations
                    pour prendre des mesures afin d'atteindre un but commun. </li>
                    
                    <div style="height:10px;font-size:10px;">&nbsp;</div>
                    <li><b>Comprendre les conséquences et l'impact de différents choix :</b> Nous ne pouvons pas revenir dans le temps pour changer une décision et voir
                    ce que l'alternative aurait donné. Par contre peut-être qu'en ayant une bonne modélisation de l'environnement, 
                    les fonctions de transition, etc. et analysant les interactions entre 
                    les agents, nous pourrions évaluer cela, ce qui semble tout de même impossible pour l'instant.</li>
                    </ul>
                
                <div style="height:30px;font-size:30px;">&nbsp;</div>
                <p style="text-align:justify; font-size:200%; font-weight:600;">
                    <b>Bibliographie</b>
                </p>
                
                <p style="text-align:justify; font-size:160%; font-weight:400;">&emsp;
                    [1] I. Arel, C. Liu, T. Urbanik, and A. Kohls, “Reinforcement learning-basedmulti-agent system for network traffic signal control,”IET IntelligentTransport Systems, 2010.
                    <br>
                    <br>
                    [2] S. Levine, C. Finn, T. Darrell, and P. Abbeel. End-to-end Training of Deep Visuomotor Policies. arXiv preprint arXiv:1504.00702, 2015.
                    <br>
                    <br>
                    [3] D. Silver, A. Huang, A., C.J. Maddison, A. Guez, L. Sifre,G. van den Driessche, J. Schrittwieser, I. Antonoglou, V. Panneershelvam, M. Lanctot, S. Dieleman, D. Grewe, J. Nham, N. Kalchbrenner, I. Sutskever, T. Lillicrap, M. Leach, K. Kavukcuoglu, T. Graepel, and D. Has-sabis. Mastering the game of go with deep neuralnetworks and tree search.Nature, 529(7587). 2016.
                    <br>
                    <br>
                    [4] D. Silver, J. Schrittwieser, K. Simonyan, I. Antonoglou, A. Huang, A. Guez, T. Hubert, L. Baker, M. Lai, A. Bolton, Y. Chen,T. Lillicrap, F. Hui, L. Sifre, G. van den Driessche, T. Graepel, and D. Hassabis. Mastering the game of go without human knowledge.Nature, 2017.
                </p>


            </div>

        </div>
    </div>
</div>


<footer class="footer-container text-center">
    <div class="container">
        <div class="row">
            <div class="col-xs-12">
                <p></p>
            </div>
        </div>
    </div>
</footer>

<script>
    document.addEventListener("DOMContentLoaded", function (event) {
        navActivePage();
    });
</script>

<!-- Google Analytics: change UA-XXXXX-X to be your site's ID 

<script>
  (function (i, s, o, g, r, a, m) {
    i['GoogleAnalyticsObject'] = r; i[r] = i[r] || function () {
      (i[r].q = i[r].q || []).push(arguments)
    }, i[r].l = 1 * new Date(); a = s.createElement(o),
      m = s.getElementsByTagName(o)[0]; a.async = 1; a.src = g; m.parentNode.insertBefore(a, m)
  })(window, document, 'script', '//www.google-analytics.com/analytics.js', 'ga');
  ga('create', 'UA-XXXXX-X', 'auto');
  ga('send', 'pageview');
</script>

-->
<script type="text/javascript" src="./main.70a66962.js"></script>
</body>

</html>
